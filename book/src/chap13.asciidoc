[[chap13]]
== Estudio de Caso: Selección de Estructura de Datos

Hasta ahora hemos aprendido sobre las principales estructuras de datos de Julia y hemos visto algunos de los algoritmos que las utilizan.

Este capítulo presenta un estudio de caso con ejercicios que le permiten practicar la elección de estructuras de datos y su uso.


=== Análisis de Frecuencia de Palabras

Como de costumbre, se recomienda intentar resolver los ejercicios antes de leer las soluciones.

[[ex13-1]]
==== Ejercicio 13-1

Escriba un programa que lea un archivo, divida cada línea en palabras, elimine el espacio en blanco y la puntuación de las palabras, y luego las convierta en minúsculas.

[TIP]
====
La función +isletter+ permite saber si un carácter pertenece al alfabeto.
(((isletter)))((("function", "Base", "isletter", see="isletter")))
====

[[ex13-2]]
==== Ejercicio 13-2

Vaya a la página de Proyecto Gutenberg (https://gutenberg.org) y descargue su libro favorito sin derechos de autor en formato de texto plano. La mayoría de los libros están en inglés, pero existen algunos en español.
(((Project Gutenberg)))

Modifique su programa del ejercicio anterior para leer el libro que descargó, omita la información del encabezado al comienzo del archivo y procese el resto de las palabras tal como en el ejercicio previo.

Luego, modifique el programa para contar la cantidad total de palabras en el libro y la cantidad de veces que se usa cada palabra.

Imprima la cantidad de palabras diferentes que se usan en el libro. Compare diferentes libros de diferentes autores, escritos en diferentes épocas. ¿Qué autor usa el vocabulario más extenso?

[[ex13-3]]
==== Ejercicio 13-3

Modifique el programa del ejercicio anterior para imprimir las 20 palabras más utilizadas en el libro.

[[ex13-4]]
==== Ejercicio 13-4

Modifique el programa anterior para que lea una lista de palabras y luego imprima todas las palabras del libro que no estén en la lista de palabras. ¿Cuántos de ellos son errores tipográficos? ¿Cuántos de ellos son palabras comunes que deberían estar en la lista de palabras, y cuántos de ellos son términos realmente macabros?

=== Números aleatorios

Dadas las mismas entradas, la mayor parte de los programas generan la misma salida cada vez que los ejecutamos, por lo que se dice que son deterministas. Normalmente el determinismo es algo bueno, ya que esperamos que un cálculo nos entregue siempre el mismo resultado. Para algunas aplicaciones, sin embargo, queremos que el computador sea impredecible. Por ejemplo en los juegos, pero hay otros casos.
(((deterministic)))

Hacer que un programa sea realmente no determinista resulta difícil, pero hay formas de que al menos parezca no determinista. Una de ellas es usar algoritmos para generar números _pseudoaleatorios_. Los números pseudoaleatorios no son verdaderamente aleatorios porque se generan mediante un cálculo determinista, pero al mirar estos números es casi imposible distinguirlos de lo aleatorio.
(((pseudorandom)))

La función +rand+ devuelve un numero de punto flotante entre +0.0+ y +1.0+ (incluyendo 0.0 pero no 1.0). Cada vez que usted llama a +rand+ obtiene el siguiente numero de una larga serie. Para ver un ejemplo, ejecute este bucle:
(((rand)))

[source,@julia-setup]
----
for i in 1:10
    x = rand()
    println(x)
end
----

La función +rand+ puede tomar un iterador o matriz como argumento y devuelve un elemento aleatorio de ellos:

[source,@julia-setup]
----
for i in 1:10
    x = rand(1:6)
    print(x, " ")
end
----

[[ex13-5]]
==== Ejercicio 13-5

Escriba una función llamada +escogerdelhistograma+ que tome un histograma definido como en <<dictionary_collection_counters>> y devuelva un valor aleatorio del histograma, elegido con probabilidad proporcional a la frecuencia. Por ejemplo, para este histograma:
(((choosefromhist)))((("function", "programmer-defined", "choosefromhist", see="choosefromhist")))

[source,@julia-repl-test chap11]
----
julia> t = ['a', 'a', 'b'];

julia> histogram(t)
Dict{Any,Any} with 2 entries:
  'a' => 2
  'b' => 1
----

su función debe devolver +pass:['a']+ con probabilidad latexmath:[\(\frac{2}{3}\)] y +pass:['b']+ con probabilidad latexmath:[\(\frac{1}{3}\)].

=== Histograma de Palabras

Debes hacer los ejercicios anteriores antes de continuar. También necesitarás https://github.com/PiensaEnJulia/PiensaEnJulia.jl/blob/master/data/DonQuijote.txt.

Aquí hay un programa que lee un archivo y construye un histograma de las palabras en el archivo:
(((processfile)))((("function", "programmer-defined", "processfile", see="processfile")))(((processline)))((("function", "programmer-defined", "processline", see="processline")))

[source,@julia-setup chap13]
----
function procesararchivo(nombrearchivo)
    hist = Dict()
    for linea in eachline(nombrearchivo)
        procesarlinea(linea, hist)
    end
    hist
end;

function procesarlinea(linea, hist)
    linea = replace(linea, '-' => ' ')
    for palabra in split(linea)
        palabra = string(filter(isletter, [palabra...])...)
        palabra = lowercase(palabra)
        hist[palabra] = get!(hist, palabra, 0) + 1
    end
end;
----

[source,@julia-eval chap13]
----
hist = procesararchivo(joinpath("..", "data", "DonQuijote.txt"));
----

[source,julia]
----
hist = procesararchivo("DonQuijote.txt");
----

Este programa lee _DonQuijote.txt_, que contiene el texto de _Don Quijote_ de Miguel de Cervantes.
(((Austen, Jane)))

+procesararchivo+ recorre las líneas del archivo, pasando una línea a la vez a +procesarlinea+. El histograma +hist+ se está utilizando como acumulador.
(((accumulator)))

+procesarlinea+ usa la función +replace+ para reemplazar los guiones por espacios antes de usar +split+ para dividir la línea en una matriz de cadenas. Recorre el conjunto de palabras y usa +filter+, +isletter+ y +lowercase+ para eliminar los signos de puntuación y convertir las palabras a minúsculas. (Decir que las cadenas se "convierten" es incorrecto; recuerde que las cadenas son inmutables, por lo que una función como +lowercase+ devuelve cadenas nuevas).
(((replace)))(((split)))(((isletter)))(((lowercase)))(((get!)))(((filter)))((("function", "Base", "filter", see="filter")))

Finalmente, +procesarlinea+ actualiza el histograma creando un nuevo elemento o incrementando uno existente.

Para contar el número total de palabras en el archivo, podemos sumar las frecuencias en el histograma:
(((totalwords)))((("function", "programmer-defined", "totalswords", see="totalwords")))

[source,@julia-setup chap13]
----
function palabrastotales(hist)
    sum(values(hist))
end
----

El número de palabras diferentes es el número de elementos en el diccionario:
(((differentwords)))((("function", "programmer-defined", "differentwords", see="differentwords")))

[source,@julia-setup chap13]
----
function palabrasdiferentes(hist)
    length(hist)
end
----

Para imprimir los resultados se puede usar el siguiente código:

[source,@julia-repl-test chap13]
----
julia> println("Número total de palabras: ", palabrastotales(hist))
Número total de palabras: 385925

julia> println("Número de palabras diferentes: ", palabrasdiferentes(hist))
Número de palabras diferentes: 23607
----


=== Palabras Más Comunes

Para encontrar las palabras más comunes, podemos hacer una matriz de tuplas, donde cada tupla contiene una palabra y su frecuencia, y ordenarla. La siguiente función toma un histograma y devuelve una matriz de tuplas de frecuencia de palabras:
(((mostcommon)))((("function", "programmer-defined", "mostcommon", see="mostcommon")))(((reverse)))(((sort)))

[source,@julia-setup chap13]
----
function mascomun(hist)
    t = []
    for (clave, valor) in hist
        push!(t, (clave, valor))
    end
    reverse(sort(t))
end
----

En cada tupla, la frecuencia aparece primero, por lo que la matriz resultante se ordena por frecuencia. A continuación se muestra un bucle que imprime las 10 palabras más comunes:

[source,julia]
----
t = mascomun(hist)
println("Las palabras más comunes son:")
for (frec, palabra) in t[1:10]
    println(palabra, "\t", frec)
end
----

En este ejemplo utilizamos un carácter de tabulación (+pass:['\t']+) como "separador", en vez de un espacio, por lo que la segunda columna está alineada. A continuación se muestran los resultados de _Don Quijote_:
(((separator)))(((\t)))

[source,@julia-eval chap13]
----
t = mascomun(hist)
println("Las palabras más comunes son:")
for (frec, palabra) in t[1:10]
    println(palabra, "\t", freq)
end
----

[TIP]
====
Este código se puede simplificar usando como argumento la palabra reservada +rev+ de la función +sort+. Puede leer sobre esto en https://docs.julialang.org/en/v1/base/sort/#Base.sort.
====


=== Parametros Opcionales

Hemos visto funciones integradas de Julia que toman argumentos opcionales. También es posible escribir funciones definidas por el programador con argumentos opcionales. Por ejemplo, aquí hay una función que imprime las palabras más comunes en un histograma:
(((optional argument)))(((printmostcommon)))((("function", "programmer-defined", "printmostcommon", see="printmostcommon")))

[source,@julia-setup chap13]
----
function imprimirmascomun(hist, num=10)
    t = mascomun(hist)
    println("Las palabras más comunes son: ")
    for (frec, palabra) in t[1:num]
        println(palabra, "\t", freq)
    end
end
----

El primer parámetro es obligatorio; el segundo es opcional. El _valor predeterminado_ de +num+ es +10+.
(((default value)))

Si solo pasas un argumento:

[source,@julia-setup chap13]
----
imprimirmascomun(hist)
----

+num+ toma el valor predeterminado. Si pasas dos argumentos:

[source,@julia-setup chap13]
----
imprimirmascomun(hist, 20)
----

+num+ toma el valor del argumento. En otras palabras, el argumento opcional _anula_ el valor predeterminado.
(((override)))

Si una función tiene parámetros obligatorios y opcionales, los parámetros obligatorios deben ir primero, seguidos de los opcionales.

[[dictionary_subtraction]]
=== Resta de Diccionario

Encontrar las palabras de un libro que no están en la lista de palabras de +palabras.txt+ es un problema similar a una resta de conjuntos; es decir, queremos encontrar todas las palabras de un conjunto (las palabras en el libro) que no están en el otro (las palabras en la lista).

+resta+ toma los diccionarios +d1+ y +d2+ y devuelve un nuevo diccionario que contiene todas las claves de +d1+ que no están en +d2+. Como realmente no nos importan los valores, los fijamos como +nothing+.
(((subtract)))((("function", "programmer-defined", "subtract", see="subtract")))(((nothing)))(((∩)))((("operator", "Base", "∩", see="∩")))

[source,@julia-setup chap13]
----
function resta(d1, d2)
    res = Dict()
    for clave in keys(d1)
        if clave ∉ keys(d2)
            res[clave] = nothing
        end
    end
    res
end
----

Para encontrar las palabras en el libro que no están en +palabras.txt+, podemos usar +procesararchivo+ para construir un histograma para +palabras.txt+, y luego la función +resta+:

[source,julia]
----
palabras = procesararchivo("palabras.txt")
dif = resta(hist, palabras)

println("Palabras en el libro que no están en la lista de palabras:")
for palabra in keys(diff)
    print(palabra, " ")
end
----

Estos son algunos de los resultados de _Don Quijote_:

[source]
----
Words in the book that aren't in the word list:
outree quicksighted outwardly adelaide rencontre jeffereys unreserved dixons betweens ...
----

Some of these words are names and possessives. Others, like “rencontre”, are no longer in common use. But a few are common words that should really be in the list!

[[ex13-6]]
==== Exercise 13-6

Julia proporciona una estructura de datos llamada +Set+ que proporciona muchas operaciones comunes de conjuntos. Puede leer sobre ellas en <<collections_and_data_structures>>, o leer la documentación en https://docs.julialang.org/en/v1/base/collections/#Set-Like-Collections-1.

Escriba un programa que use la resta de conjuntos para encontrar palabras en el libro que no están en la lista de palabras.

=== Palabras al Azar

Para elegir una palabra aleatoria del histograma, el algoritmo más simple es construir una matriz con múltiples copias de cada palabra, de acuerdo con la frecuencia observada, y luego elegir una palabra de la matriz:
(((randomword)))((("function", "programmer-defined", "randomword", see="randomword")))

[source,@julia-setup chap13]
----
function palabraalazar(h)
    t = []
    for (palabra, frec) in h
        for i in 1:frec
            push!(t, palabra)
        end
    end
    rand(t)
end
----

Este algoritmo funciona, pero no es muy eficiente; cada vez que elige una palabra aleatoria, reconstruye la matriz, que es tan grande como el libro original. Una mejora es construir la matriz una vez y luego hacer múltiples selecciones, pero la matriz sigue siendo grande.

Una alternativa es:

. Use las +claves+ para obtener una matriz de palabras del libro.

. Cree una matriz que contenga la suma acumulada de las frecuencias de palabras (vea <<ex10-2>>). El último elemento en esta matriz es el número total de palabras en el libro, latexmath:[\(n\)].

. Elija un número aleatorio del 1 al latexmath:[\(n\)]. Use búsqueda binaria (vea <<ex10-10>>) para encontrar el índice donde se insertará el número aleatorio en la suma acumulada.
(((búsqueda de bisección)))

. Use el índice para encontrar la palabra correspondiente en la matriz de palabras.

[[ex13-7]]
==== Ejercicio 13-7

Escriba un programa que use este algoritmo para elegir una palabra aleatoria del libro.

[[markov_analysis]]
=== Análisis de Markov

Si elige palabras del libro al azar, puedes tener una idea del vocabulario usado, pero probablemente no obtendremos una oración:

[source]
----
rocinante pláticas sazón ojos Dulcinea Dios
----

Una serie de palabras aleatorias rara vez tiene sentido porque no hay relación entre palabras sucesivas. Por ejemplo, en una oración real, esperaría que un artículo como "el" sea seguido por un sustantivo, y probablemente no un verbo o un adverbio.

Una forma de medir este tipo de relaciones es con el análisis de Markov, que define para una secuencia dada de palabras, la probabilidad de las palabras que podrían venir después. Por ejemplo, en la canción _La vida es un carnaval_ (de Celiz Cruz):
(((Markov analysis)))

[verse]
____
Todo aquel
Que piense que la vida siempre es cruel
Tiene que saber que no es así
Que tan solo hay momentos malos
Y todo pasa

Todo aquel
Que piense que esto nunca va cambiar
Tiene que saber que no es así
Que al mal tiempo, buena cara
Y todo cambia

Ay, no hay que llorar (No hay que llorar)
Que la vida es un carnaval
Que es más bello vivir cantando
____

En este texto, la frase "que piense" siempre va seguida de la palabra "que", pero la frase "piense que" puede ir seguida de "la" o "esto".

El resultado del análisis de Markov es un mapeo de cada prefijo (como "que piense" y "piense que") a todos los sufijos posibles (como "la" y "esto").
(((prefix)))(((suffix)))

Dada esta asignación, puede generar un texto aleatorio comenzando con cualquier prefijo y eligiendo aleatoriamente entre los posibles sufijos. A continuación, puede combinar el final del prefijo y el nuevo sufijo para formar el siguiente prefijo y repetir.

Por ejemplo, si comienza con el prefijo "Que la", la siguiente palabra será "vida", porque el prefijo solo aparece dos veces en el texto y siempre está seguido de este sufijo. El siguiente prefijo es "la vida", por lo que el siguiente sufijo podría ser "siempre" o "es".

En este ejemplo, la longitud del prefijo siempre es dos, pero puede hacer análisis de Markov con un prefijo de cualquier longitud.

[[ex13-8]]
==== Ejercicio 13-8

Análisis de Markov:

. Escriba un programa que lea un texto desde un archivo y realice análisis de Markov. El resultado debe ser un diccionario que asocie prefijos y una colección de posibles sufijos. La colección puede ser una matriz, tupla o diccionario; depende de usted hacer una elección adecuada. Puede probar su programa con una longitud de prefijo de dos, pero debe escribir el programa de manera tal que sea fácil probar con otras longitudes.

. Agregue una función al programa anterior para generar texto aleatorio basado en análisis de Markov. Aquí hay un ejemplo de Don Quijote con longitud de prefijo 2:
+
[quote]
____
“He was very clever, be it sweetness or be angry, ashamed or only amused, at such a stroke. She had never thought of Hannah till you were never meant for me?" "I cannot make speeches, Emma:" he soon cut it all himself.”
____
+
For this example, I left the punctuation attached to the words. The result is almost syntactically correct, but not quite. Semantically, it almost makes sense, but not quite.
+
What happens if you increase the prefix length? Does the random text make more sense?

. Once your program is working, you might want to try a mash-up:  if you combine text from two or more books, the random text you generate will blend the vocabulary and phrases from the sources in interesting ways.

Credit: This case study is based on an example from Kernighan and Pike, The Practice of Programming, Addison-Wesley, 1999.

[TIP]
=====
Debes hacer este ejercicio antes de continuar.
=====

=== Estructuras de Datos

Usar análisis de Markov para generar texto aleatorio es divertido, pero además, este ejercicio tiene un trasfondo: la selección de la estructura de datos. En los los ejercicios anteriores, tenía que elegir:

* Cómo representar los prefijos.

* Cómo representar la colección de los posibles sufijos.

* Cómo representar la asociación de cada prefijo con la colección de posibles sufijos.

El último es fácil: un diccionario es la opción obvia para una asociación entre claves y valores correspondientes.

Para los prefijos, las opciones más obvias son cadena, matriz de cadenas o tupla de cadenas.

Para los sufijos, puede ser una matriz o un histograma (diccionario).

¿Cómo se elige? El primer paso es pensar en las operaciones que deberá implementar para cada estructura de datos. Para los prefijos, debemos ser capaces de eliminar palabras del principio y agregarlas al final. Por ejemplo, si el prefijo actual es "que piense" y la siguiente palabra es "que", debe poder formar el siguiente prefijo, "piense que".

Para los prefijos, podría elegir una matriz, ya que en ella es fácil agregar y eliminar elementos.

Para la colección de sufijos, las operaciones que debemos realizar incluyen agregar un nuevo sufijo (o aumentar la frecuencia de uno existente) y elegir un sufijo aleatorio.

Agregar un nuevo sufijo es igualmente fácil para la implementación de la matriz o el histograma. Elegir un elemento aleatorio de una matriz es fácil; elegir eficientemente de un histograma es más difícil (ver <<ex13-7>>).

Hasta ahora hemos hablado principalmente sobre la facilidad de implementación, pero hay otros factores a considerar al elegir las estructuras de datos. Uno es el tiempo de ejecución. A veces hay una razón teórica para esperar que una estructura de datos sea más rápida que otra; por ejemplo, anteriormente se mencionó que el operador +in+ es más rápido para los diccionarios que para las matrices, al menos cuando el número de elementos es grande.

Pero generalmente no se sabe de antemano qué implementación será más rápida. Una opción es implementar ambos y ver cuál es mejor. Este enfoque se llama _benchmarking_. Una alternativa práctica es elegir la estructura de datos que sea más fácil de implementar y luego ver si es lo suficientemente rápida para la aplicación prevista. Si es así, no hay necesidad de continuar. Si no, hay herramientas, como el módulo +Profile+, que pueden identificar los lugares en un programa que toman más tiempo.
(((benchmarking)))

El otro factor a considerar es el espacio de almacenamiento. Por ejemplo, usar un histograma para la colección de sufijos puede tomar menos espacio porque solo tiene que almacenar cada palabra una vez, sin importar cuántas veces aparezca en el texto. En algunos casos, ahorrar espacio también puede hacer que su programa se ejecute más rápido. En el peor de los casos, su programa podría no ejecutarse si se queda sin memoria. Pero para muchas aplicaciones, el espacio es una consideración secundaria después del tiempo de ejecución.

Una última reflexión: en esta discusión, he dado a entender que deberíamos usar una estructura de datos para el análisis y la generación. Pero dado que estas son fases separadas, también sería posible usar una estructura para el análisis y luego convertirla en otra estructura para la generación. Esta sería una ganancia neta si el tiempo ahorrado durante la generación excede el tiempo dedicado a la conversión.


One final thought: in this discussion, I have implied that we should use one data structure for both analysis and generation. But since these are separate phases, it would also be possible to use one structure for analysis and then convert to another structure for generation. This would be a net win if the time saved during generation exceeded the time spent in conversion.

[TIP]
====
The Julia package +DataStructures+ (see https://github.com/JuliaCollections/DataStructures.jl) implements a variety of data structures.
====


=== Debugging

When you are debugging a program, and especially if you are working on a hard bug, there are five things to try:
(((debugging)))

Reading:: 
Examine your code, read it back to yourself, and check that it says what you meant to say.

Running::
Experiment by making changes and running different versions. Often if you display the right thing at the right place in the program, the problem becomes obvious, but sometimes you have to build scaffolding.

Ruminating:: 
Take some time to think! What kind of error is it: syntax, runtime, or semantic? What information can you get from the error messages, or from the output of the program? What kind of error could cause the problem you’re seeing? What did you change last, before the problem appeared?

Rubberducking:: 
If you explain the problem to someone else, you sometimes find the answer before you finish asking the question. Often you don’t need the other person; you could just talk to a rubber duck. And that’s the origin of the well-known strategy called rubber duck debugging. I am not making this up; see https://en.wikipedia.org/wiki/Rubber_duck_debugging.
(((rubber duck debugging)))

Retreating:: 
At some point, the best thing to do is back off, undoing recent changes, until you get back to a program that works and that you understand. Then you can start rebuilding.

Beginning programmers sometimes get stuck on one of these activities and forget the others. Each activity comes with its own failure mode.

For example, reading your code might help if the problem is a typographical error, but not if the problem is a conceptual misunderstanding. If you don’t understand what your program does, you can read it 100 times and never see the error, because the error is in your head.

Running experiments can help, especially if you run small, simple tests. But if you run experiments without thinking or reading your code, you might fall into a pattern I call “random walk programming”, which is the process of making random changes until the program does the right thing. Needless to say, random walk programming can take a long time.
(((random walk programming)))

You have to take time to think. Debugging is like an experimental science. You should have at least one hypothesis about what the problem is. If there are two or more possibilities, try to think of a test that would eliminate one of them.

But even the best debugging techniques will fail if there are too many errors, or if the code you are trying to fix is too big and complicated. Sometimes the best option is to retreat, simplifying the program until you get to something that works and that you understand.

Beginning programmers are often reluctant to retreat because they can’t stand to delete a line of code (even if it’s wrong). If it makes you feel better, copy your program into another file before you start stripping it down. Then you can copy the pieces back one at a time.

Finding a hard bug requires reading, running, ruminating, and sometimes retreating. If you get stuck on one of these activities, try the others.


=== Glossary

deterministic::
Pertaining to a program that does the same thing each time it runs, given the same inputs.
(((deterministic)))

pseudorandom::
Pertaining to a sequence of numbers that appears to be random, but is generated by a deterministic program.
(((pseudorandom)))

default value::
The value given to an optional parameter if no argument is provided.
(((default value)))

override::
To replace a default value with an argument.
(((override)))

benchmarking::
The process of choosing between data structures by implementing alternatives and testing them on a sample of the possible inputs.
(((benchmarking)))

rubber duck debugging::
Debugging by explaining your problem to an inanimate object such as a rubber duck. Articulating the problem can help you solve it, even if the rubber duck doesn’t know Julia.
(((rubber duck debugging)))


=== Exercises

[[ex13-9]]
==== Exercise 13-9

The “rank” of a word is its position in an array of words sorted by frequency: the most common word has rank 1, the second most common has rank 2, etc.

Zipf’s law describes a relationship between the ranks and frequencies of words in natural languages (https://en.wikipedia.org/wiki/Zipfpass:[&apos;]s_law). Specifically, it predicts that the frequency, latexmath:[\(f\)], of the word with rank latexmath:[\(r\)] is:
(((Zipf’s law)))

[latexmath]
++++
\begin{equation}
{f = c r^{-s}}
\end{equation}
++++
where latexmath:[\(s\)] and latexmath:[\(c\)] are parameters that depend on the language and the text. If you take the logarithm of both sides of this equation, you get:

[latexmath]
++++
\begin{equation}
{\log f = \log c - s \log r}
\end{equation}
++++
So if you plot latexmath:[\(\log f\)] versus latexmath:[\(\log r\)], you should get a straight line with slope latexmath:[\(-s\)] and intercept latexmath:[\(\log c\)].

Write a program that reads a text from a file, counts word frequencies, and prints one line for each word, in descending order of frequency, with latexmath:[\(\log f\)] and latexmath:[\(\log r\)].

Install a plotting library:
(((Plots)))((("module", "Plots", see="Plots")))

[source,jlcon]
----
(v1.0) pkg> add Plots
----

Its usage is very easy:
(((plot)))((("function", "Plots", "plot", see="plot")))

[source,julia]
----
using Plots
x = 1:10
y = x.^2
plot(x, y)
----

Use the +Plots+ library to plot the results and check whether they form a straight line.

